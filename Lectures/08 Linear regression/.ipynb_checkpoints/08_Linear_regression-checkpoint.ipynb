{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08-Linear regression\n",
    "\n",
    "This notebook shows how to perform simple and multiple linear regression in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have seen how to do simple data analysis, e.g. `value_counts`, `describe`, `corr` etc. \n",
    "\n",
    "In linear regression, we take the analysis one step further by estimating a line that quantifies the relationship between variables in our data. \n",
    "\n",
    "OLS (ordinary least squares) is the most common method for finding the regression line. In OLS, we find the intercept and slope of the line by minimizing the sum of the squared *residuals*, i.e, the difference between the predicted value by the line and the actual value.\n",
    "\n",
    "<img src=\"images/sale_price_area.png\" width = \"45%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the OLS estimator from the package `statsmodels`. The sub-module `formula` allows us to fit statistical models using R-style formulas.\n",
    "\n",
    "We import `statsmodels` by giving it the shorter name `smf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple linear regression, we use data to estimate the relationship between a variable $y$ and a single variable $x$:\n",
    "\n",
    "$y_i = \\alpha + \\beta x_i $\n",
    "\n",
    "where:\n",
    "- $y$ is the dependent variable\n",
    "- $x$ is the explanatory (independent) variable\n",
    "- $\\alpha$ is the constant term (i.e., intercept)\n",
    "- $\\beta$ is the slope of the regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore the variation in cars' fuel economy (mpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df = pd.read_excel('data/mpg.xlsx')\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mpg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying `corr` on the `DataFrame`, we see that there is a strong negative relationship between fuel economy and horsepower (-0.778)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = round(mpg_df.corr(numeric_only = True).loc['horsepower', 'mpg'], 2)\n",
    "\n",
    "print(correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a scatter plot between `mpg` and `horsepower`, and add the correlation coefficient as a title to the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(mpg_df['horsepower'], mpg_df['mpg'])\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('mpg')\n",
    "\n",
    "# Add title\n",
    "ax.set_title('R = ' + str(correlation))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that there are a few missing observations in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before estimating a statistical model, we should use `dropna` in order to drop all rows with missing observations.\n",
    "\n",
    "When applying `dropna` on a `DataFrame`, it will drop *all* rows with `NaN`. Therefore, we specify `subset = ['mpg', 'horsepower']` so that we only drop the rows with `NaN` in the columns that we will be using in our linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.dropna(subset = ['mpg', 'horsepower'], axis = 0, inplace = True)\n",
    "\n",
    "len(mpg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are estimating the following model:\n",
    "\n",
    "$mpg_i = \\alpha + \\beta \\times horsepower_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by transforming the model to a R-style formula. Note that we do not have to add a constant term (i.e., intercept) to the model formula as it will be added automatically by `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'mpg ~ horsepower'\n",
    "\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an OLS model by using the `ols` function from `statsmodels`. \n",
    "\n",
    "`ols` requires two inputs: \n",
    "1. model formula\n",
    "2. data that we want to estimate the model with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OLS model\n",
    "model = smf.ols(formula, data = mpg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have created the OLS model, we must apply `fit` on our model object in order to actually *estimate* the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate model\n",
    "model = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see the regression results, we must apply `summary` on our fitted model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table contains a lof of information that is stored in the attributes of our fitted model object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `param` attribute contains the model coefficients, i.e., intercept and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params['horsepower']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `bse` attribute contains the standard errors of the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `rsquared` and `rsquared_adj` attributes of contains the model's R-squared and adjusted R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.rsquared_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù **Note:** The R-squared measures the share of variation in the dependent variable (y) that is explained by our model. In this example, over 60% of the variation in cars' fuel economy in our data can be explained by the number of horsepower alone. Not bad for such a simple model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    \n",
    "<p> The file <TT>survey_data.csv</TT> contains the results from a survey of 2,884 individuals regarding their earnings. Import the file and store it in a variable called <TT>df_wage</TT>:\n",
    "    \n",
    "1. Estimate a simple linear regression model in which hourly earnings (column <TT>hourly_earnings</TT>) is the dependent variable and years of schooling (column <TT>years_schooling</TT>) is the explanatory variable. Store the model in a variable called <TT>mod_wage</TT>.\n",
    "2. Print the model's $\\beta$ coefficient. Does hourly earnings change a lot for each additional year of schooling?\n",
    "3. Print the model's adjusted R-squared. Does years of schooling appear to be a good predictor of variation in hourly earnings?\n",
    "\n",
    "PS: Don't overwrite previous variable names.\n",
    "    \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-sample prediction\n",
    "\n",
    "Once we have estimated the OLS model, can use it to predict values of the dependent variable given observations of the explanatory variable. By creating these predictions, it also becomes easy to visualize the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate predictions, we apply `predict` on the fitted model object. \n",
    "\n",
    "`predict` will calculate the predicted value for the dependent variable using the estimates from the regression model and the observed value on the explanatory variable for each observation in the data that was used to estimate the model. This is known as *in-sample* prediction.\n",
    "\n",
    "We can store the predictions in the original `DataFrame` by assigning the predicted values to a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and store in-sample predictions\n",
    "mpg_df['pred'] = model.predict(mpg_df)\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a line plot of `pred` on the $y$-axis, and `horsepower` on the $x$-axis. This will give us the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.sort_values('horsepower', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Line plot\n",
    "ax.plot(mpg_df['horsepower'], mpg_df['pred'], color = 'black', label = 'OLS line')\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('mpg')\n",
    "\n",
    "# Add title and legend\n",
    "ax.set_title(formula)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a scatter plot of actual `mpg` and `horsepower` in the same plot with the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(mpg_df['horsepower'], mpg_df['mpg'])\n",
    "\n",
    "# Line plot\n",
    "ax.plot(mpg_df['horsepower'], mpg_df['pred'], color = 'black', label = 'OLS line')\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('mpg')\n",
    "\n",
    "# Add title and legend\n",
    "ax.set_title(formula)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    \n",
    "<p> Use the simple linear regression model from the previous exercise to generate in-sample predictions of hourly earnings given the observed years of schooling for each respondent in the survey data.\n",
    "    \n",
    "Show a scatter plot with years of schooling on the $x$-axis and hourly earnings on the $y$-axis, and add the regression line to the plot using the in-sample predictions.\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect visually how well our fitted model explains variation in fuel economy:\n",
    "- First, we plot *actual* `mpg` against *actual* `mpg`. This will create a 45 degree line.\n",
    "- Second, we add a scatter plot of *actual* `mpg` and *predicted* `pred`.\n",
    "\n",
    "The idea is that the closer the predictions in the scatter plot are to the 45 degree line, the better job does our model at explaining the variation in fuel economy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# 45 degree line\n",
    "mpg_df.sort_values('mpg', inplace = True)\n",
    "ax.plot(mpg_df['mpg'], mpg_df['mpg'], color = 'black', label = '45-degree line')\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(mpg_df['mpg'], mpg_df['pred'])\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Actual mpg')\n",
    "ax.set_ylabel('Predicted mpg')\n",
    "ax.set_title(formula)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three potential cases for the observations in the scatter plot:\n",
    "- Observation is below the 45 degree line &rarr; the model *underpredicts* `mpg`\n",
    "- Observation is on the 45 degree line &rarr; the model correctly predicts `mpg`\n",
    "- Observation is above the 45 degree line &rarr; the model *overpredicts* `mpg`\n",
    "\n",
    "From the plot, we see that the model does a good job at predicting fuel economy at low levels of `mpg`. However, at high levels of `mpg`, the model systematically underpredicts the fuel economy of the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<h3> Your turn </h3>\n",
    "    \n",
    "<p> Use the in-sample predictions from the previous exercise, and show a scatter plot with actual hourly earnings on the $x$-axis and predicted hourly earnings on the $y$-axis. Add a 45 degree line of actual hourly earnings in the plot. \n",
    "    \n",
    "Does it seem like the linear regression model does a good job at predicting hourly earnings based only on years of schooling? Or does the model systematically over- or underpredict hourly earnings for some respondents?\n",
    "    \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several other potential explanatory variables of fuel economy in our data. However, if we want to use a different variable than `horsepower`, we have two options:\n",
    "\n",
    "- Re-write our program above using a new explanatory variable. Boring...\n",
    "- Write a function that estimates an OLS model for any given explanatory variable. Fun üòÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create two functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `get_predictions` estimates an OLS model given two inputs: 1) a model formula and 2) data. The function creates in-sample predictions and returns a *copy* of the original data with the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(formula, df):\n",
    "    \"\"\"Fit a linear regression model given a model formula and return df with in-sample predictions.\"\"\"\n",
    "    \n",
    "    # Copy dataframe (important! Otherwise, we change the original df)\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Create and fit OLS model\n",
    "    model = smf.ols(formula, data = df_copy).fit()\n",
    "\n",
    "    # Add predictions to copied dataframe\n",
    "    df_copy['pred'] = model.predict(df_copy)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `plot_predictions` plots the predictions along with the 45 degree line given two inputs: 1) a model formula and 2) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(formula, df):\n",
    "    \"\"\"Plot in-sample predictions along 45-degree line given a model formula.\"\"\"\n",
    "\n",
    "    # Get yvar from formula\n",
    "    depvar = formula.split('~')[0].strip()\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # 45 degree line\n",
    "    df.sort_values(depvar, inplace = True)\n",
    "    ax.plot(df[depvar], df[depvar], color = 'black', label = '45-degree line')\n",
    "\n",
    "    # Scatter plot\n",
    "    ax.scatter(df[depvar], df['pred'])\n",
    "\n",
    "    # Formatting\n",
    "    ax.set_xlabel(depvar)\n",
    "    ax.set_ylabel('pred')\n",
    "    ax.set_title(formula)\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us re-run the estimation above, but using our new functions instead. \n",
    "\n",
    "We re-importing the data to remove columns with predictions from previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df = pd.read_excel('data/mpg.xlsx')\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 1: estimate the model and get in-sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formula\n",
    "formula = 'mpg ~ weight'\n",
    "\n",
    "# Estimate model and get in-sample predictions (store in new df)\n",
    "mpg_df_new = get_predictions(formula, mpg_df)\n",
    "\n",
    "mpg_df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that original data has not been altered (because we copied the df)\n",
    "# mpg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step 2: Plot predictions along the 45 degree line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plot_predictions(formula, mpg_df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù  **Note:** Recall that it is possible to pass the output of a function call directly as an input to another function call in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'mpg ~ weight'\n",
    "plot_predictions(formula, get_predictions(formula, mpg_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression\n",
    "\n",
    "In multiple linear regression, we expand the simple model to include multiple explanatory variables:\n",
    "\n",
    "$y_i = \\alpha + \\beta_1 x_{i, 1} + \\beta_2 x_{i, 2} + \\beta_3 x_{i, 3}$ ...\n",
    "\n",
    "In general, we can increase the explanatory power of our model (i.e., the R-squared) by including more explanatory variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df = pd.read_excel('data/mpg.xlsx')\n",
    "mpg_df.dropna(inplace = True)\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`corr` shows that there is also a high correlation between a car's fuel economy and its weight (-0.832)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now estimate the following model:\n",
    "\n",
    "$mpg_i = \\alpha + \\beta_1 \\times horsepower_i + \\beta_2 \\times weight_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expand the model formula with weight as an explanatory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'mpg ~ horsepower + weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols(formula, data = mpg_df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the functions that we created above to generate the prediction plot for the new model with the two explanatory variables `horsepower` and `weight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(formula, get_predictions(formula, mpg_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the new model does a good job at explaining the variation in fuel economy, we would expect the predictions to be close to actual observations. However, we see that the model still underpredicts fuel economy for high levels of mpg despite including a second explanatory variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side note**: When a linear regression model includes more than one predictor (i.e., explanatory variable), we can no longer generate the regression line from the in-sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions from regression model with two explanatory variables\n",
    "formula = 'mpg ~ horsepower + weight'\n",
    "df_temp = get_predictions(formula, mpg_df)\n",
    "df_temp.sort_values('horsepower', inplace = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(df_temp['horsepower'], df_temp['mpg'])\n",
    "\n",
    "# Line plot\n",
    "ax.plot(df_temp['horsepower'], df_temp['pred'], color = 'black', label = 'OLS line')\n",
    "\n",
    "# Add axis labels\n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('mpg')\n",
    "\n",
    "# Add title and legend\n",
    "ax.set_title(formula)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    \n",
    "<p> Expand the simple linear regression model from previous exercises to also take into account the number of years of work experience:\n",
    "\n",
    "- Estimate the model: $hourly\\_earnings_i = \\alpha + \\beta_1 \\times years\\_schooling_i + \\beta_2 \\times experience_i$\n",
    "- Print the model's adj. R-squared. Does including years of experience improve the explanatory power of the model?\n",
    "- Generate the in-sample predictions from the model and display a scatter plot of actual vs predicted hourly earnings along the 45-degree line.\n",
    "    \n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Polynomials\n",
    "\n",
    "Polynomial regression is a good option when the relationship between the dependent and explanatory variables does not seem to be linear. Instead of estimating a regression line, we fit a *curve* to the data. \n",
    "\n",
    "<img src=\"images/polynomial_regression.png\" width = \"65%\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, in our fuel economy data, there seems to be a non-linear relationship between cars' fuel economy and horsepower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df = pd.read_excel('data/mpg.xlsx')\n",
    "mpg_df.dropna(subset = ['horsepower', 'mpg'], inplace = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(mpg_df['horsepower'], mpg_df['mpg'])\n",
    "\n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('mpg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of estimating a linear regression model, we now estimate a polynomial model. Specifically, we estimate a 2nd order polynomial model by adding the *square* of the explanatory variable to our model formula:\n",
    "\n",
    "$mpg_i = \\alpha + \\beta_1 \\times horsepower_i + \\beta_2 \\times horsepower_i^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R-style formula, we can include the squared explanatory variable by adding the term `I(horsepower**2)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_poly = 'mpg ~ horsepower + I(horsepower**2)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate OLS model\n",
    "model_poly = smf.ols(f_poly, mpg_df).fit()\n",
    "\n",
    "# Model summary\n",
    "model_poly.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again use our function `get_predictions` to generate a new `DataFrame` with the in-sample predictions, but now from our polynomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create in-sample predictions\n",
    "mpg_df = get_predictions(f_poly, mpg_df)\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use `plot_predictions` to visually inspect how well the model predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(f_poly, mpg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, it seems that 2nd order polynomial model does a better job at predicting fuel economy compared to the simple regression model, although the model still slightly underpredicts fuel economy at high levels of `mpg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    \n",
    "<p> Expand the multiple linear regression model from the previous exercise with the following polynomial term:\n",
    "\n",
    "$hourly\\_earnings_i = \\alpha + \\beta_1 \\times years\\_schooling_i + \\beta_2 \\times experience_i + \\beta_3 \\times experience_i^2$\n",
    "\n",
    "Display a scatter plot of actual vs predicted hourly earnings from the model along the 45 degree line. Does it seem like adding the polynomial term has improved the model's ability to predict the hourly earnings of the respondents?\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Side note**: Although our model of fuel economy is no longer a simple regression model due to the second polynomial term, note that we are technically still using only one variable (i.e., horsepower) to explain variation in fuel economy. In that case, we can visualize the regression line using the predicted values the same way as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.sort_values('horsepower', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Line plot\n",
    "ax.plot(mpg_df['horsepower'], mpg_df['pred'], color = 'black', label = 'OLS line')\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(mpg_df['horsepower'], mpg_df['mpg'])\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('horsepower')\n",
    "ax.set_ylabel('mpg')\n",
    "ax.set_title(f_poly)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical variables\n",
    "\n",
    "So far, we have only used *numerical* variables as explanatory variables in our regression models. \n",
    "\n",
    "However, in data analysis, we often work with *categorical* data, i.e., observations are categories/labels and not numbers. For example, in timeseries data, we cannot say that the value \"January\" is smaller or larger than the value \"July\", or that \"1am\" is more or less than \"3pm\".\n",
    "\n",
    "However, we can still use non-numerical variables as a explanatory variables in regression models, but we must include then as *categorical* variables. Such variables are also known as factor or indicator variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our `mpg` data contains the categorical variable `origin`. In fact, the average fuel economy is very different for cars from the US compared to cars from Europe and Japan, and `origin` could therefore be an important explanatory variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df.groupby('origin')['mpg'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In R-style formula, we can include categorical variables by adding the term `C(origin)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cat = 'mpg ~ horsepower + C(origin)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> üìù  **Note:** By adding categorical variables in a regression model, we create a different constant term for each group/category in the data, i.e., the regression line has a different intercept for each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the regression results below, we see that there is still a negative relationship between `mpg` and `horsepower`. \n",
    "\n",
    "However, there is now a different intercept for American, Japanese and European cars. The intercept for European cars is 38.3695, while the intercept is +2.7510 higher for Japanese cars and -2.4253 lower for American cars. This means that Japanese cars tend to be more fuel efficient than European cars, and European cars are more fuel efficient than American cars, even when they have the same number of horsepower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols(f_cat, mpg_df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can use our function `plot_predictions` to plot the predictions from the model with `origin` along the 45 degree line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(f_cat, get_predictions(f_cat, mpg_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<h3> Your turn</h3>\n",
    "    \n",
    "<p> Estimate a multiple linear regression model of hourly earnings that also takes into account whether the respondent works in the public or private sector. Use the survey data and estimate the model\n",
    "\n",
    "$hourly\\_earnings_i = \\alpha + \\beta_1 \\times years\\_schooling_i + \\beta_2 \\times experience_i + \\beta_3 \\times sector_i$,\n",
    "\n",
    "where $sector_i$ is a categorical variable (\"private\" or \"public\"). \n",
    "\n",
    "On average, how much less do respondents in the public sector earn compared to respondents in the private sector?\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical vs numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, datasets often have variables that can be interpreted both as categorical and numerical. \n",
    "\n",
    "For example, in `mpg`, should we interpret `cylinders` as a numerical variable or a categorical variable? Although the variable is numerical (int), it has only a few unique values and could potentially by included as a categorical variable in a regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df['cylinders'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first estimate a regression model with both `horsepower` and `cylinders` as numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model formula\n",
    "f_cyl_num = 'mpg ~ horsepower + cylinders'\n",
    "\n",
    "# Estimate OLS model and show output\n",
    "model_cyl_num = smf.ols(f_cyl_num, mpg_df).fit()\n",
    "model_cyl_num.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can instead estimate a model in which we include `cylinders` as a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model formula\n",
    "f_cyl_cat = 'mpg ~ horsepower + C(cylinders)'\n",
    "\n",
    "# Estimate OLS model and show output\n",
    "model_cyl_cat = smf.ols(f_cyl_cat, mpg_df).fit()\n",
    "model_cyl_cat.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite both models including `cylinders` as an explanatory variable, we see that including `cylinders` as a categorical variable actually increases the explanatory power of our model (i.e., adj. R-squared) from 65.5 to 70.1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(model_cyl_num.rsquared_adj, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(model_cyl_cat.rsquared_adj, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Exercise 1: Outliers in hourly earnings\n",
    "\n",
    "The file `survey_data.csv` contains information on the hourly earnings (in DKK) of 2,884 respondents. In statistical analysis, the presence of outliers (i.e., extreme values) can have a large impact on the results of the estimation and how well the model predicts the observed outcome. Therefore, in this exercise, you will investigate the presence of outliers in the survey data and its effect on the estimates from a linear regression model.\n",
    "\n",
    "**Task 1**: Load the data and do the following:\n",
    "- Calculate the number of respondents that had an hourly wage of less than 10 DKK or above 1000 DKK.\n",
    "- Calculate the average hourly wage for males and females in the private and public sector.\n",
    "- Create a single plot that shows histograms of the hourly earnings for males and females seperately.\n",
    "\n",
    "**Task 2**: Create a function called `get_beta` that estimates a regression model and returns the beta coefficient for a specific explanatory variable. The function should take three inputs: `df` (the dataset), `formula` (formula for the regression model), and `exp` (column name of an explanatory variable). \n",
    "\n",
    "Test the function by estimating the following regression model\n",
    "\n",
    "$hourly\\_earnings_i = \\alpha + \\beta_1 \\times years\\_schooling_i + \\beta_2 \\times experience_i + \\beta_3 \\times experience_i^2$,\n",
    "\n",
    "and print the $\\beta$-coefficient on the number of years of schooling.\n",
    "\n",
    "**Task 3**: There are some respondents in the data that have an extremely high or low hourly wage. We want to explore how much dropping a single observation, i.e., respondent, from our data affects the estimated coefficient on years of schooling in the regression model from the previous task. \n",
    "\n",
    "1. Write a `for` loop where you in each iteration:\n",
    "    - drop an observation from the data\n",
    "    - use `get_beta` to retrieve the coefficient on years of schooling\n",
    "    - store the coefficient in a list\n",
    "   \n",
    "   *Note*: In the first iteration you should drop the first respondent from the data. In the second iteration you should keep the first respondent but drop the second respondent. In the third iteration you should keep the first and second respondents, but drop the third one, and so on...\n",
    "    \n",
    "2. Use the list with the estimated coefficients on years of schooling from the previous task and display the distribution of the coefficients in a histogram. What is your verdict? Does it seem that the $\\beta$ coefficient on `years_schooling` is affected by the presence of outliers?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Exercise 2: Fuel economy and polynomials\n",
    "\n",
    "We have estimated a 2nd order polynomial model in which we used the number of horsepower to explain variation in fuel economy. However, there could also be a non-linear relationship between fuel economy and other car attributes. Including polynomial terms can often improve the explanatory power of our regression models. Therefore, in this exercise, you will explore the adjusted R-squared from using different car attributes in a 2nd order polynomial model.\n",
    "\n",
    "\n",
    "**Task 1**: Create a function called `get_rsqr` that estimates a regression model and returns the model's adjusted R-squared. The function should take two inputs: `df` (the dataset) and `formula` (formula for the regression model). Import the `mpg` data and test the function by estimating the model\n",
    "\n",
    "$mpg_i = \\alpha + \\beta_1 \\times horsepower_i + \\beta_2 \\times horsepower_i^2$,\n",
    "\n",
    "and print the adjusted R-square from the model.\n",
    "\n",
    "**Task 2**: We now want to compare the adjusted R-squared from the 2nd order polynomial model in the previous task, but using four different car attributes: `horsepower`, `weight`, `acceleration` and `model_year`. \n",
    "\n",
    "Write a `for` loop where you in each iteration:\n",
    "- Update the model formula for the polynomial model to include one of the four car attributes\n",
    "- Use the function `get_rsqr` to get the adjusted R-squared from the model.\n",
    "- Print the adjusted R-squared from each of the polynomial models\n",
    "    \n",
    "*Note*: In each iteration, the polynomial model should include only one car attribute. In the first iteration, the model should use `horsepower`; in the second iteration, the model should use `weight`; and so on.\n",
    "\n",
    "Which 2nd order polynomial model has the highest adj. R-squared?\n",
    "\n",
    "**Task 3**: In addition to comparing the adjusted R-squared, we also want to inspect the estimated regression line from each of the polynomial models with the four different car attributes: `horsepower`, `weight`, `acceleration` and `model_year`. \n",
    "\n",
    "Create a single graph with four subplots side-by-side (1x4). In each subplot:\n",
    "- Show a scatter plot with one of the car attributes on the $x$-axis and `mpg` on the $y$-axis.\n",
    "- Show the regression line using the in-sample predictions from the polynomial model with the car attrbitue\n",
    "- Add the adjusted R-squared from the polynomial model in the title of the sub-plot\n",
    "\n",
    "*Hint*: Use a `for` loop to iterate over the axes object to avoid duplicating the code for generating each subplot. Note also that you can use the function `get_predictions` from the lecture to get a `DataFrame` with the in-sample predictions for each polynomial model.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Exercise 3: Drivers of CO2 emissions\n",
    "\n",
    "In this exercise, you are asked to explore CO2 emissions around the world, and potential drivers for why some countries have higher emissions than other countries. To do this, you are given two datasets.\n",
    "\n",
    "The first file `co2_emissions.csv` contains the following country-level data on CO2 emissions in 2021:\n",
    "- `country`: Country name\n",
    "- `year`: Year of observation\n",
    "- `co2_total`: Total carbon dioxide (CO2) emissions (Mt CO2e)\n",
    "- `population`: Total population\n",
    "\n",
    "In addition, the file contains data on the following six potential explanatory variables of country-level CO2 emissions: \n",
    "- `urban`: Urban population (% of total population)\n",
    "- `gdp_pc`: GDP per capita (current US$)\n",
    "- `electricity`: Access to electricity (% of population)\n",
    "- `agriculture`: Agricultural land (% of land area)\n",
    "- `nat_resources`: Total natural resources rents (% of GDP)\n",
    "- `renew_energy`: Renewable energy consumption (% of total final energy consumption)\n",
    "\n",
    "Note that the emissions dataset contains data not only for countries, but also for aggregates such as \"Africa Eastern and Southern\" and \"Heavily indebted poor countries (HIPC)\". \n",
    "\n",
    "The second file `country_info.csv` contains information about the countries and aggregates observed in the emissions dataset:\n",
    "- `name`: Name of the location (country or aggregate)\n",
    "- `region`: Region of the location\n",
    "- `incomeLevel`: Income level of the location (e.g., \"Low income\")\n",
    "\n",
    "**Task 1**: Create a dataset that contains countries only:\n",
    "\n",
    "1. Import and merge the two datasets. Explore the merged data, e.g., data types, missing values, unique values etc.\n",
    "2. Drop all observations that are not countries, e.g., \"Africa Eastern and Southern\" so that the data contains observations for countries only.\n",
    "3. Create a new column called `co2_pc`, which is the *per capita* CO2 emissions (t CO2e/capita) for each country.\n",
    "\n",
    "   *Hint*: Multiple total CO2 emissions with 1,000,000 to convert from million tons to tons (otherwise, you'll get very small numbers).\n",
    "\n",
    "**Task 2**: Use the country-level dataset from the previous task to visualize CO2 emissions across countries: \n",
    "\n",
    "1. Create a figure with two subplots:\n",
    "    - In the first subplot, show a scatter plot of total population (`population`) and per capita CO2 emissions (`co2_pc`).\n",
    "    - In the second subplot, show a histogram of the distribution of per capita CO2 emissions (`co2_pc`).\n",
    "   \n",
    "   From the plots, are there any outliers in the data?\n",
    "   \n",
    "2. Create a figure with 6 subplots (either 2x3 or 3x2):\n",
    "    - In each subplot, show a scatter plot of per capita CO2 emissions (`co2_pc`) and one of the potential explanatory variables of emissions (`urban`, `gdp_pc`, `electricity`, `agriculture`, `nat_resources`, `renew_energy`).\n",
    "    - Add the correlation coefficient between the explanatory variable and per capita CO2 emissions in the  title of the subplot.\n",
    "\n",
    "   *Hint*: To avoid using a nested `for` loop to generate the 2x3 or 3x2 plot, you can apply the `flatten` method on the `ax` object to create a one-dimensional object that you can use a single `for` loop to iterate over.\n",
    "\n",
    "**Task 3**: You will now estimate a multiple linear regression model where per-capita CO2 emissions (`co2_pc`) is the depdenent variable, and the model includes three out of the six potential explanatory variables: `urban`, `gdp_pc`, `electricity`, `agriculture`, `nat_resources`, `renew_energy`. \n",
    "\n",
    "*Note*: Do not include any polynomial terms in the model.\n",
    "\n",
    "In general, there are 20 possible combinations when you can choose three explanatory variables from six different variables. Your task is to find the combination of three variables that has the highest adjusted R-squared. \n",
    "\n",
    "Write a `for` loop in which you loop over the 20 possible combinations of three explanatory variables. For each possible combination:\n",
    "- Estimate the linear regression model: $co2\\_pc_i = \\alpha + \\beta_1 \\times X1_i + \\beta_2 \\times X2_i + \\beta_3 \\times X3_i$\n",
    "- Extract the adjusted R-squared from the model\n",
    "\n",
    "Which combination of explanatory variables has the highest adjusted R-squared?\n",
    "\n",
    "*Hint*: The function `combinations` from `itertools` can be used to generate all possible combinations from a set of values (see [here](https://www.geeksforgeeks.org/python/python-itertools-combinations-function/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
