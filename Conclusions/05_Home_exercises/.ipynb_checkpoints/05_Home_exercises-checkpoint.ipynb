{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb8f0d7-33a7-45e9-9c58-49a27de1cd0b",
   "metadata": {},
   "source": [
    "# 05 - Pandas basics\n",
    "\n",
    "This notebook contains solution proposals to the home exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b932a7e-801e-4da9-9b56-80f755a718f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f61d509-d71a-4c9f-9bd5-d1ee9c15eb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b03b883-267a-4ac5-96a8-542054f0f30f",
   "metadata": {},
   "source": [
    "### ðŸ“š Exercise 1: Fuel economy\n",
    "\n",
    "The file `mpg.xlsx` contains observations on fuel economy and six additional attributes for 398 different car models. The column `mpg` is a measure of the car's fuel economy, i.e. the number of miles per gallon of petrol.\n",
    "\n",
    "Import the file and store it as a `DataFrame` in a variable called `mpg_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dffcd07-b63a-4ea1-a369-150e7c9615a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_df = pd.read_excel('mpg.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b573f12-8c13-4cce-8b4a-d8d26d01f72e",
   "metadata": {},
   "source": [
    "**Task 1**: Explore the data by answering the following questions:\n",
    "1. Which columns in the <code>DataFrame</code> are strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0a09ea-6026-4686-8b82-84b2b9f17a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of datatypes:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   horsepower    392 non-null    float64\n",
      " 3   weight        398 non-null    int64  \n",
      " 4   acceleration  398 non-null    float64\n",
      " 5   model_year    398 non-null    int64  \n",
      " 6   origin        398 non-null    object \n",
      " 7   name          398 non-null    object \n",
      "dtypes: float64(3), int64(3), object(2)\n",
      "memory usage: 25.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Print overview of data types\n",
    "print('Overview of datatypes:\\n')\n",
    "print(mpg_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def22317-f67b-4c31-a5f1-e77645ad0e5d",
   "metadata": {},
   "source": [
    "2. What is the average number of miles per gallon of the car models in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55bb524-a7d6-4a97-8780-02e91de1f175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean of mpg from descriptives...\n",
    "mean_mpg = mpg_df.describe().loc['mean', 'mpg']\n",
    "# ...or use \"mean\" function on mpg column\n",
    "# mean_mpg = mpg_df['mpg'].mean()\n",
    "print(f'Average mpg: {mean_mpg:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36d27b-d585-4ca7-9822-cb70ccecd52e",
   "metadata": {},
   "source": [
    "3. What are the unique number of cylinders observed in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2f071-ebf2-49fd-a996-54ad38b75601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of unique cylinders\n",
    "print(f'Number of unique values of cylinders: {mpg_df['cylinders'].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5da283-e177-4b9b-a081-16266eb2bc24",
   "metadata": {},
   "source": [
    "4. How many of the car models in the data were from Europe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72fe1e5-2aca-468f-b8b2-49eb55516cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value count of origin\n",
    "origin = mpg_df['origin'].value_counts()\n",
    "print(f'Number of car models from Europe: {origin.loc['europe']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006f85d-a850-4514-8bea-5a632c093774",
   "metadata": {},
   "source": [
    "5. What is the correlation between cars' fuel economy and horsepower?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526746e-f79f-486f-88b3-c0deff402e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print correlation between mpg and horsepower\n",
    "correlation = mpg_df['mpg'].corr(mpg_df['horsepower'])\n",
    "print(f'Correlation between mpg and horsepower: {correlation:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655c75ca-da09-4e51-be49-4a97f5cec009",
   "metadata": {},
   "source": [
    "6. Are there any missing observations in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852a524-39c2-45d6-9ba5-cdc8a018925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of missing values\n",
    "print('Overview of NaN:\\n')\n",
    "print(mpg_df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7c3a7-d8c9-4095-9af9-f5c49d48f272",
   "metadata": {},
   "source": [
    "**Task 2**: Transform the data by performing the following operations:\n",
    "1. The column `model_year` ranges from 1970 to 1982, but it contains only the last two digits of the year. Change the column so that it also contains the two first digits, e.g., '74' should be '1974'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eef817-837c-4c5d-85a3-511b1445b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative 1: convert to string and then add the string \"19\" to the beginning of each year\n",
    "mpg_df['model_year'] = mpg_df['model_year'].astype('str')\n",
    "mpg_df['model_year'] = '19' + mpg_df['model_year']\n",
    " \n",
    "# Alternative 2: keep as integer and simply add 1900 to each year\n",
    "#mpg_df['model_year'] = mpg_df['model_year'] + 1900\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ea9bad-5887-41f3-a83f-bd208471b8e5",
   "metadata": {},
   "source": [
    "2. Convert the data type of the column `model_year` to `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a626e9b-ca78-4c0f-82d9-3aa706b43fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: not necessary to specify format as pandas is able to detect the format in this case\n",
    "mpg_df['model_year'] = pd.to_datetime(\n",
    "    mpg_df['model_year'], \n",
    "    format = '%Y' # not necessary to specify format as pandas is able to detect the format (year) in this case\n",
    ")\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42ae72-3ea8-4032-839c-5a910af722c6",
   "metadata": {},
   "source": [
    "3. Drop the rows with missing observations on `horsepower` and store the new `DataFrame` in a variable called `mpg_df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d8c3dd-214d-4bfc-8325-499464367940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing from original dataframe\n",
    "mpg_df2 = mpg_df.dropna(\n",
    "    subset = 'horsepower', # not necessary to specify subset as \"horsepower\" is the only column with nans\n",
    "    axis = 0\n",
    ")\n",
    "\n",
    "mpg_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f06deb-3eec-4416-a7a0-079e68972702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that nans were dropped\n",
    "mpg_df2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b9878-0db1-43c6-a7c4-324692d05ca4",
   "metadata": {},
   "source": [
    "4. Instead of dropping the rows with missing values, you want to replace missing values in `horsepower`by the *origin-specific* sample mean of `horsepower`. Create a new column in `mpg_df` called `hp_imputed` that contains the observations on `horsepower`. Then, replace the missing values in `hp_imputed` with the average value of `horsepower` given the origin of the car.\n",
    "\n",
    "   For each origin in the data ('usa', 'europe', or 'japan'):\n",
    "   - Filter rows on origin and calculate the sample mean of `horsepower`\n",
    "   - Use `loc` to fill missing values in `hp_imputed` with sample mean in rows of given origin\n",
    "   - *Hint: To avoid code redundency, use a `for` loop with the following statement:*\n",
    "     ```\n",
    "     for origin in mpg_df['origin'].unique():\n",
    "     ```\n",
    "You should inspect the data to verify that the operation worked as expected and that missing values in `hp_imputed` have in fact been replaced by origin-specific sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04040d23-e92a-440e-bc77-a1aac30a55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column with horsepower\n",
    "mpg_df['hp_imputed'] = mpg_df['horsepower']\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb46cc1-152b-4be6-97f0-b49e793b8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over unique origins in the data\n",
    "for origin in mpg_df['origin'].unique():\n",
    "\n",
    "    # Calculate origin-specific mean\n",
    "    mean = mpg_df[mpg_df['origin'] == origin]['horsepower'].mean()\n",
    "\n",
    "    # Replace missing values in hp_imputed with origin-specific mean\n",
    "    mpg_df.loc[(mpg_df['hp_imputed'].isna()) & (mpg_df['origin'] == origin), 'hp_imputed'] = mean\n",
    "\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c0fd0f-cb33-4e68-80e6-2a2370bc7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are no missing in the new column\n",
    "mpg_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44eb544-66e1-40fa-a572-699208aeb8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rows in which horsepower has been imputed\n",
    "mpg_df[mpg_df['horsepower'] != mpg_df['hp_imputed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a8c6c-63b2-485f-b21b-d25c4eaa1b66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bce27008-ef06-48ed-9bc5-590734f49f4b",
   "metadata": {},
   "source": [
    "### ðŸ“š Exercise 2: Electricity consumption\n",
    "\n",
    "The file `eurostat.xlsx` contains data on electricity consumption (in gigawatt-hours) for European countries from 2001 to 2023. \n",
    "\n",
    "**Task 1**: Import the file and store it in a variable called `df_euro`. Note that the file contains many unecessary rows and columns. Transform the `DataFrame` so that:\n",
    "- the index is the country (incl. EU and Euro area)\n",
    "- the columns are the years from 2001 to 2023\n",
    "\n",
    "The final `DataFrame` should have 43 rows and 23 columns.\n",
    "\n",
    "*Hint*: use optional parameters in `read_excel` (e.g., `skipfooter`) to control how the file is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce9778-9b29-4fd1-b4e2-9690793b6c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file\n",
    "df_euro = pd.read_excel(\n",
    "    'eurostat.xlsx', \n",
    "    sheet_name = 'Sheet 1',           # Specify which sheet to import\n",
    "    skiprows = list(range(9)) + [10], # Skip rows at the top of the file\n",
    "    skipfooter = 5,                   # Skip rows at the bottom of the file\n",
    ")\n",
    "\n",
    "df_euro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2472f0-34d4-4faa-8a0b-f97682893611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of years as strings\n",
    "years = [str(i) for i in range(2001, 2024)]\n",
    "\n",
    "# Keep only columns with country and year observations\n",
    "df_euro = df_euro[['TIME'] + years]\n",
    "\n",
    "# Use country column as index\n",
    "df_euro.set_index('TIME', inplace = True)\n",
    "\n",
    "df_euro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da13e2b-134c-4caf-b2da-14198a5ea713",
   "metadata": {},
   "source": [
    "**Task 2**: Use `df_euro` and calculate the following:\n",
    "- Average electricity consumption in Finland from 2001 to 2023\n",
    "- Sum of electricity consumption in all countries (not incl. EU and Euro area) in 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6701cd5-62e8-4046-bd47-750f148459da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we don't have any rows with missing values\n",
    "# But that is because missing values are indicated with \":\"\n",
    "df_euro.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aaf8ba-c46e-4ac5-b8cf-7f138df59243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note also that this causes many columns to be objects instead of numeric\n",
    "df_euro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c674ffe5-9afc-4889-a913-44ee48fb868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use replace function to change these values to NaN\n",
    "df_euro.replace(':', np.nan, inplace = True)\n",
    "\n",
    "# Most columns contain NaNs now\n",
    "df_euro.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d7893-501d-47ae-8c12-e603cfc17c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns are now numeric and we can calculate the statistics\n",
    "df_euro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40bd2f6-aacd-4bed-b6cb-a73a81227b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fin = df_euro.loc['Finland'].mean()\n",
    "print(f'Average annual electricity consumption in Finland, 2001-2023: {avg_fin:,.2f} GWh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9f761-4038-4f8d-8507-20dcc242f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_22 = df_euro.loc['Belgium':, '2022'].sum()\n",
    "print(f'Sum of electricity consumption in Europe in 2022: {avg_22:,.2f} GWh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465a5f4-c2b5-42bf-8407-5043cc9b1588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Can use the \"na_values\" parameter in \"read_excel\" to specify values that should be interpreted as nan\n",
    "# df_euro = pd.read_excel(\n",
    "#     'eurostat.xlsx', \n",
    "#     sheet_name = 'Sheet 1',           \n",
    "#     skiprows = list(range(9)) + [10], \n",
    "#     skipfooter = 5,                   \n",
    "#     na_values = ':'                  # Specify additional nan values\n",
    "# )\n",
    "\n",
    "# Note: This would have ensured that columns are imported as numeric and no longer need to replace these values\n",
    "# df_euro.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee46416-4e93-4a97-9d0e-22d6f836232c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e14af00-cbb6-4c29-bf5d-19d0bba8bbd2",
   "metadata": {},
   "source": [
    "### ðŸ“š Exercise 3: Labor market statistics\n",
    "\n",
    "The file `FRED_monthly.csv` contains time series for the US economy for each month from 1948 to 2024. The column `UNRATE` is the average monthly unemployment rate. \n",
    "\n",
    "Import the file and store it in a variable called `df_fred`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de466153-0415-46d6-b35a-83f451f37968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import file\n",
    "df_fred = pd.read_csv('FRED_monthly.csv')\n",
    "\n",
    "# Create decade column\n",
    "df_fred['Decade'] = (df_fred['Year'] // 10) * 10\n",
    "\n",
    "df_fred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42512b0d-2402-4908-a8b4-82d39144b246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "df_fred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3af99e-e2e6-45b4-a45d-bbae13f52c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missings\n",
    "df_fred.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef19aee-3176-4c0a-8ab9-b974a7b07144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check descriptives\n",
    "df_fred.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abaff8f-8808-4b44-9ea1-700615876d7c",
   "metadata": {},
   "source": [
    "**Task 1**: Use the `df_fred` to calculate and print the following:\n",
    "- Average unemployment rate in the data from 1948 to 2024.\n",
    "- Average unemployment rate for each *decade* in the data from 1950 to 2010 for which you have all the observations.\n",
    "\n",
    "*Hint*: The decade can be computed from the `Year` column using truncated integer division:\n",
    "```\n",
    "df_fred[Year] // 10 * 10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb5509-bea7-493d-bc25-b61d2b76d194",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tot = df_fred['UNRATE'].mean()\n",
    "print(f'Average unempoyment rate 1948-2024: {avg_tot:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d91540-0657-49f2-803f-4f1522a3a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dec in df_fred['Decade'].unique():\n",
    "    if dec != 2020:\n",
    "        # Filter on decade\n",
    "        subset = df_fred[df_fred['Decade'] == dec]\n",
    "        \n",
    "        # Calculate average unemployment rate in subset\n",
    "        avg_dec = subset['UNRATE'].mean()\n",
    "\n",
    "        # Print average unemployment rate\n",
    "        print(f\"Average unemployment rate in the {dec}'s: {avg_dec:.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8ce0e-84d2-4159-8a8f-d3b6b68f026e",
   "metadata": {},
   "source": [
    "**Task 2**: Create a new `DataFrame` called `df_fred_year`, which contains the average annual unemployment rate for each year in `FRED_monthly.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530fa3a2-8deb-4eec-ae58-4c22c9088d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df_fred['Year'].unique()\n",
    "avgs = []\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    # Filter on year\n",
    "    subset = df_fred[df_fred['Year'] == year]\n",
    "\n",
    "    # Calculate average unemployment rate in subset\n",
    "    avg_year = subset['UNRATE'].mean()\n",
    "\n",
    "    # Append average unemployment rate\n",
    "    avgs.append(avg_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f13a9b-23e1-4518-9a38-785442c3d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fred_year = pd.DataFrame({'Year' : years, 'UNRATE' : avgs})\n",
    "\n",
    "df_fred_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5801beb4-d9a4-457b-8152-38c5604d9f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2ed1f3-67d7-4763-9076-b61a8dc350ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
