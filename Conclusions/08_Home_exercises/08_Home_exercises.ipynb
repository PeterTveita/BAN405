{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3577c89e-1a6a-4351-a54d-cafc9be27af4",
   "metadata": {},
   "source": [
    "# 08 - Linear regression\n",
    "\n",
    "This notebook contains solution proposals to the home exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52932143-0a69-4dda-bca7-4b5bbaab2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from itertools import combinations\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427cb09a-2a43-4678-bb75-0e754ff4108a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bfa0071-c57b-41a8-b3f6-1adfc539bc62",
   "metadata": {},
   "source": [
    "### ðŸ“š Exercise 1: Outliers in hourly earnings\n",
    "\n",
    "The file `survey_data.csv` contains information on the hourly earnings (in DKK) of 2,884 respondents. In statistical analysis, the presence of outliers (i.e., extreme values) can have a large impact on the results of the estimation and how well the model predicts the observed outcome. Therefore, in this exercise, you will investigate the presence of outliers in the survey data and its effect on the estimates from a linear regression model.\n",
    "\n",
    "**Task 1**: Load the data and do the following:\n",
    "- Calculate the number of respondents that had an hourly wage of less than 10 DKK or above 1000 DKK.\n",
    "- Calculate the average hourly wage for males and females in the private and public sector.\n",
    "- Create a single plot that shows histograms of the hourly earnings for males and females seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d9861-1316-42ae-be95-dd0988826e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wage = pd.read_csv('data/survey_data.csv', sep = ':')\n",
    "\n",
    "print(len(df_wage))\n",
    "df_wage.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015a5822-ebee-402f-adc4-762957cdcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "# df_wage.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb56181-9c1b-430b-80cf-d07b5b44e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "# df_wage.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35a420-b74d-4b19-847c-02776610cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check respondent with unusually low or high hourly earnings\n",
    "df_wage[(df_wage['hourly_earnings'] < 10) | (df_wage['hourly_earnings'] > 1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0112a-78a4-4736-a5cb-65781a44491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_wage[(df_wage['hourly_earnings'] < 10) | (df_wage['hourly_earnings'] > 1000)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b468ca-c13c-4c08-a61e-acd5f0830951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average hourly earnings by sex and sector\n",
    "df_wage.groupby(['sex', 'sector'])['hourly_earnings'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea8e79f-3e16-410a-84ed-c7fd07675e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract males and females\n",
    "males = df_wage[df_wage['sex'] == 'male'].copy()\n",
    "females = df_wage[df_wage['sex'] == 'female'].copy()\n",
    "\n",
    "print('Number of males: {}'.format(len(males)))\n",
    "print('Number of females: {}'.format(len(females)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4bd4c-d573-4810-99c6-43877aa720ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (6, 4))\n",
    "\n",
    "# Historgram: females\n",
    "ax.hist(\n",
    "    females['hourly_earnings'], \n",
    "    bins = 100, \n",
    "    alpha = 0.5, # increase transparency\n",
    "    label = 'Females',\n",
    "    density = True\n",
    ")      \n",
    "\n",
    "# Historgram: males\n",
    "ax.hist(\n",
    "    males['hourly_earnings'], \n",
    "    bins = 100, \n",
    "    alpha = 0.5, # increase transparency\n",
    "    label = 'Males',\n",
    "    density = True\n",
    ")     \n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Hourly earnings (DKK)')\n",
    "ax.set_ylabel('Share of repondents')\n",
    "ax.set_title('Histogram of hourly earnings by sex')\n",
    "ax.set_xlim(0, 2000) # remove outliers from histogram\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4369a0-dc32-4f83-8e8a-2044f024452b",
   "metadata": {},
   "source": [
    "**Task 2**: Create a function called `get_beta` that estimates a regression model and returns the beta coefficient for a specific explanatory variable. The function should take three inputs: `df` (the dataset), `formula` (formula for the regression model), and `exp` (column name of an explanatory variable). \n",
    "\n",
    "Test the function by estimating the following regression model\n",
    "\n",
    "$hourly\\_earnings_i = \\alpha + \\beta_1 \\times years\\_schooling_i + \\beta_2 \\times experience_i + \\beta_3 \\times experience_i^2$,\n",
    "\n",
    "and print the $\\beta$-coefficient on the number of years of schooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0577c86-c2ce-417b-b919-a560883455e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(df, formula, exp):\n",
    "    \"\"\"Estimate linear regression model and return beta coefficient on an explanatory variable\"\"\"\n",
    "\n",
    "    # Create and fit OLS model\n",
    "    mod = smf.ols(formula, data = df).fit()\n",
    "        \n",
    "    # Return beta coefficient\n",
    "    return mod.params[exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed6665-e4e2-4d61-83d3-a8cf18518f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formula\n",
    "f = 'hourly_earnings ~ years_schooling + experience + I(experience**2)'\n",
    "\n",
    "# Drop respondents (i.e., rows) in case there are missing values\n",
    "df_wage2 = df_wage.dropna(subset = ['hourly_earnings', 'years_schooling', 'experience'], axis = 0)\n",
    "\n",
    "# Print beta coefficient on years of schooling\n",
    "xvar = 'years_schooling'\n",
    "coef = get_beta(df_wage2, f, xvar)\n",
    "print(f'One additional year of schooling is associated with a {coef:.2f} DKK change in hourly earnings.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c607e6aa-22b5-4ce2-8fb7-1428b798caf1",
   "metadata": {},
   "source": [
    "**Task 3**: There are some respondents in the data that have an extremely high or low hourly wage. We want to explore how much dropping a single observation, i.e., respondent, from our data affects the estimated coefficient on years of schooling in the regression model from the previous task. \n",
    "\n",
    "1. Write a `for` loop where you in each iteration:\n",
    "    - drop an observation from the data\n",
    "    - use `get_beta` to retrieve the coefficient on years of schooling\n",
    "    - store the coefficient in a list\n",
    "   \n",
    "   *Note*: In the first iteration you should drop the first respondent from the data. In the second iteration you should keep the first respondent but drop the second respondent. In the third iteration you should keep the first and second respondents, but drop the third one, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dc05bd-7f85-4592-9b52-900e8ad73222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store beta coefficients\n",
    "coef_lst = []\n",
    "\n",
    "for i in df_wage2['respondentID'].unique():\n",
    "    \n",
    "    # Drop respondent i from sample\n",
    "    df_temp = df_wage2.loc[df_wage2['respondentID'] != i]\n",
    "    \n",
    "    # Get beta coefficent\n",
    "    coef = get_beta(df_temp, f, xvar)\n",
    "    \n",
    "    # Append to list\n",
    "    coef_lst.append(coef)\n",
    "\n",
    "print(len(coef_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bfafb-c497-4d3d-a463-c4641d41ea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(coef_lst))\n",
    "print(min(coef_lst))\n",
    "print(np.mean(coef_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6daf0-37e1-4a3f-812c-69df33600baa",
   "metadata": {},
   "source": [
    "2. Use the list with the estimated coefficients on years of schooling from the previous task and display the distribution of the coefficients in a histogram. What is your verdict? Does it seem that the $\\beta$ coefficient on `years_schooling` is affected by the presence of outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234aab90-5693-4dd7-b336-9bc881291ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (7, 3))\n",
    "\n",
    "# Histogram of coefficients\n",
    "ax.hist(coef_lst, bins = 150, density = True)\n",
    "\n",
    "# Add vertical lines\n",
    "ax.axvline(np.mean(coef_lst), color = 'red', linestyle = '-', label = 'mean')\n",
    "ax.axvline(min(coef_lst), color = 'red', linestyle = '--', label = 'min')\n",
    "ax.axvline(max(coef_lst), color = 'red', linestyle = ':', label = 'max')\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_ylabel('Density (%)')\n",
    "ax.set_title('Histogram of coefficient on years of schooling')\n",
    "ax.legend(loc = 'upper center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d3f83-a8f3-43ab-a48a-c66fde22741b",
   "metadata": {},
   "source": [
    "Conclusion: The presence of outliers, i.e., respondents with unusually high or low hourly earnings does not seem to affect the estimated beta coefficient on the years of schooling too much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c66ee-d032-4d3e-bb61-da076a63c9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66691dfc-6c34-42d3-9168-b4de17b58093",
   "metadata": {},
   "source": [
    "### ðŸ“š Exercise 2: Fuel economy and polynomials\n",
    "\n",
    "We have estimated a 2nd order polynomial model in which we used the number of horsepower to explain variation in fuel economy. However, there could also be a non-linear relationship between fuel economy and other car attributes. Including polynomial terms can often improve the explanatory power of our regression models. Therefore, in this exercise, you will explore the adjusted R-squared from using different car attributes in a 2nd order polynomial model.\n",
    "\n",
    "\n",
    "**Task 1**: Create a function called `get_rsqr` that estimates a regression model and returns the model's adjusted R-squared. The function should take two inputs: `df` (the dataset) and `formula` (formula for the regression model). Import the `mpg` data and test the function by estimating the model\n",
    "\n",
    "$mpg_i = \\alpha + \\beta_1 \\times horsepower_i + \\beta_2 \\times horsepower_i^2$,\n",
    "\n",
    "and print the adjusted R-square from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07f901-5ea1-47b3-b693-3491181917fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsqr(df, formula):\n",
    "    \"\"\"Estimate a linear regression model and return the adj. R-squared from the model.\"\"\"\n",
    "    \n",
    "    # Create and fit an OLS model\n",
    "    model = smf.ols(formula, data = df).fit()\n",
    "    \n",
    "    # Store adj. R-squared\n",
    "    rsqr = model.rsquared_adj\n",
    "    \n",
    "    return rsqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7635f-9b28-451a-a00c-9a205dea6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mpg data\n",
    "mpg_df = pd.read_excel('data/mpg.xlsx')\n",
    "\n",
    "print(len(mpg_df))\n",
    "mpg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fbaa50-2a82-4af2-99b1-b14949c47c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values\n",
    "# mpg_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f5b3b-817e-4f39-b055-4e64a00fb65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define formula\n",
    "f = 'mpg ~ horsepower + I(horsepower**2)'\n",
    "\n",
    "# Drop car models (i.e., rows) in case there are missing values\n",
    "mpg_df2 = mpg_df.dropna(subset = ['mpg', 'horsepower'], axis = 0)\n",
    "\n",
    "# Print adj. R-squared from model\n",
    "rsqr = get_rsqr(mpg_df2, f)\n",
    "print(f'Adjusted R-squared from model: {rsqr:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c2d78-855c-4f3c-a908-a4994c7a7d17",
   "metadata": {},
   "source": [
    "**Task 2**: We now want to compare the adjusted R-squared from the 2nd order polynomial model in the previous task, but using four different car attributes: `horsepower`, `weight`, `acceleration` and `model_year`. \n",
    "\n",
    "Write a `for` loop where you in each iteration:\n",
    "- Update the model formula for the polynomial model to include one of the four car attributes\n",
    "- Use the function `get_rsqr` to get the adjusted R-squared from the model.\n",
    "- Print the adjusted R-squared from each of the polynomial models\n",
    "    \n",
    "*Note*: In each iteration, the polynomial model should include only one car attribute. In the first iteration, the model should use `horsepower`; in the second iteration, the model should use `weight`; and so on.\n",
    "\n",
    "Which 2nd order polynomial model has the highest adj. R-squared?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcfa74-a2d2-4b88-abdd-7a0afab02d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "xvars = ['horsepower', 'weight', 'acceleration', 'model_year']\n",
    "\n",
    "for xvar in xvars:\n",
    "\n",
    "    # Update model formula\n",
    "    f = 'mpg ~ ' + xvar + ' + I(' + xvar + '**2)'\n",
    "\n",
    "    # Estimate model and get adj. R-squared\n",
    "    df_temp = mpg_df.dropna(subset = ['mpg', xvar], axis = 0)\n",
    "    rsqr = get_rsqr(df_temp, f)\n",
    "\n",
    "    print(f'Model: {f}')\n",
    "    print(f'... Adjusted R-squred: {rsqr:.3f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58951172-7fb5-4e7f-91fe-537e20b416c9",
   "metadata": {},
   "source": [
    "Conclusion: The model with the highest explanatory power is the 2nd order polynomial model with weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0822f8-e119-4b46-a215-e93e24c32a20",
   "metadata": {},
   "source": [
    "**Task 3**: In addition to comparing the adjusted R-squared, we also want to inspect the estimated regression line from each of the polynomial models with the four different car attributes: `horsepower`, `weight`, `acceleration` and `model_year`. \n",
    "\n",
    "Create a single graph with four subplots side-by-side (1x4). In each subplot:\n",
    "- Show a scatter plot with one of the car attributes on the $x$-axis and `mpg` on the $y$-axis.\n",
    "- Show the regression line using the in-sample predictions from the polynomial model with the car attrbitue\n",
    "- Add the adjusted R-squared from the polynomial model in the title of the sub-plot\n",
    "\n",
    "*Hint*: Use a `for` loop to iterate over the axes object to avoid duplicating the code for generating each subplot. Note also that you can use the function `get_predictions` from the lecture to get a `DataFrame` with the in-sample predictions for each polynomial model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a57f1e-de38-460d-ab99-470ad5cd1314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(formula, df):\n",
    "    \"\"\"Fit a linear regression model given a model formula and return df with in-sample predictions.\"\"\"\n",
    "    \n",
    "    # Copy dataframe (important! Otherwise, we change the original df)\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Create and fit OLS model\n",
    "    model = smf.ols(formula, data = df_copy).fit()\n",
    "\n",
    "    # Add predictions to copied dataframe\n",
    "    df_copy['pred'] = model.predict(df_copy)\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea46463-3fc9-4d1c-b96f-56a650a6bae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list with car attributes\n",
    "xvars = ['horsepower', 'weight', 'acceleration', 'model_year']\n",
    "\n",
    "# Create 1x4 figure with scatter plots and regression lines\n",
    "fig, ax = plt.subplots(ncols = 4, figsize = (13, 3))\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    # Generate predictions for a specific car attribute\n",
    "    f = 'mpg ~ ' + xvars[i] + ' + I(' + xvars[i] + '**2)'\n",
    "    df_temp = get_predictions(f, mpg_df.dropna(subset = ['mpg', xvars[i]], axis = 0))\n",
    "    df_temp.sort_values(xvars[i], inplace = True)\n",
    "\n",
    "    # Add R-sqaure from model in title\n",
    "    rsqr = get_rsqr(df_temp, f)\n",
    "    ax[i].set_title(f'Adj. R-squared: {rsqr:.3f}')\n",
    "\n",
    "    # Show scatter plot between mpg and explanatory variable\n",
    "    ax[i].scatter(df_temp[xvars[i]], df_temp['mpg'])\n",
    "\n",
    "    # Add regression line from polynomial model\n",
    "    ax[i].plot(df_temp[xvars[i]], df_temp['pred'], c = 'black', label = 'OLS line')\n",
    "\n",
    "    # Formatting\n",
    "    ax[i].set_xlabel(xvars[i])\n",
    "    ax[i].set_ylabel('mpg')\n",
    "    ax[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb759f8-7acf-439c-82bf-f8814afcc70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b29bc4-1711-4360-80a4-37850cef8884",
   "metadata": {},
   "source": [
    "### ðŸ“š Exercise 3: Drivers of CO2 emissions\n",
    "\n",
    "In this exercise, you are asked to explore CO2 emissions around the world, and potential drivers for why some countries have higher emissions than other countries. To do this, you are given two datasets.\n",
    "\n",
    "The first file `co2_emissions.csv` contains the following country-level data on CO2 emissions in 2021:\n",
    "- `country`: Country name\n",
    "- `year`: Year of observation\n",
    "- `co2_total`: Total carbon dioxide (CO2) emissions (Mt CO2e)\n",
    "- `population`: Total population\n",
    "\n",
    "In addition, the file contains data on the following six potential explanatory variables of country-level CO2 emissions: \n",
    "- `urban`: Urban population (% of total population)\n",
    "- `gdp_pc`: GDP per capita (current US$)\n",
    "- `electricity`: Access to electricity (% of population)\n",
    "- `agriculture`: Agricultural land (% of land area)\n",
    "- `nat_resources`: Total natural resources rents (% of GDP)\n",
    "- `renew_energy`: Renewable energy consumption (% of total final energy consumption)\n",
    "\n",
    "Note that the emissions dataset contains data not only for countries, but also for aggregates such as \"Africa Eastern and Southern\" and \"Heavily indebted poor countries (HIPC)\". \n",
    "\n",
    "The second file `country_info.csv` contains information about the countries and aggregates observed in the emissions dataset:\n",
    "- `name`: Name of the location (country or aggregate)\n",
    "- `region`: Region of the location\n",
    "- `incomeLevel`: Income level of the location (e.g., \"Low income\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ab19be-b3a4-4f1a-bc26-340b2b87dfc3",
   "metadata": {},
   "source": [
    "**Task 1**: Create a dataset that contains countries only:\n",
    "\n",
    "1. Import and merge the two datasets. Explore the merged data, e.g., data types, missing values, unique values etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1a3577-2b9e-4243-8395-dc343a93ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import emissions data\n",
    "df_co2 = pd.read_csv('data/co2_emissions.csv')\n",
    "\n",
    "# Import location info data\n",
    "df_info = pd.read_csv('data/country_info.csv')\n",
    "df_info.rename(columns = {'name' : 'country'}, inplace = True)\n",
    "\n",
    "# Merge the data\n",
    "df_co2 = df_co2.merge(df_info, on = 'country', how = 'left')\n",
    "\n",
    "print(df_co2['country'].nunique())\n",
    "df_co2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2773f37-1a76-4709-b09d-828d0e232d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: data types (looks good)\n",
    "# df_co2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee73a5-8b20-4485-bddb-b3a05c80a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: data contains non-countries\n",
    "df_co2['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198e3f77-802a-42f0-8882-181ebcad827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: several columns contain missing values\n",
    "df_co2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18028cfd-ce96-434c-be60-2056201ba55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: several unique regions in the data\n",
    "df_co2['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215932d5-bfcf-43f8-90eb-fca5f0478947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Aggregates can be identified with the region column\n",
    "# df_co2[(df_co2['region'] == 'Aggregates') | (df_co2['region'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944795d-d646-4bbf-a256-38c88e23ca0c",
   "metadata": {},
   "source": [
    "2. Drop all observations that are not countries, e.g., \"Africa Eastern and Southern\" so that the data contains observations for countries only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429b5e5-45db-407c-a8b0-62711764ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observatons with missing region info\n",
    "df_co2.dropna(subset = ['region'], inplace = True)\n",
    "\n",
    "# Drop aggregate regions, i.e. non-countries\n",
    "df_co2 = df_co2[df_co2['region'] != 'Aggregates'].copy()\n",
    "\n",
    "print(f'Number of countries: {df_co2['country'].nunique()}')\n",
    "df_co2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e8a11-3bed-4472-bd25-0504e2adbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: unique countries (looks good)\n",
    "# df_co2['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f494614c-4330-4d38-ab81-9854e04d405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: but still some observations with missing values\n",
    "df_co2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb37e4d-a40b-4b78-8cf0-3bfbe1377b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: some countries with missing co2 data\n",
    "# df_co2[df_co2['co2_total'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83821609-be7d-4833-bc5e-79ba97b8070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop countries with missing co2 data (no reason to keep them)\n",
    "df_co2 = df_co2[df_co2['co2_total'].notna()].copy()\n",
    "\n",
    "print(df_co2['country'].nunique())\n",
    "df_co2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5811661d-9bd4-4860-9a67-4e53c55b9119",
   "metadata": {},
   "source": [
    "3. Create a new column called `co2_pc`, which is the *per capita* CO2 emissions (t CO2e/capita) for each country.\n",
    "   \n",
    "   *Hint*: Multiple total CO2 emissions with 1,000,000 to convert from million tons to tons (otherwise, you'll get very small numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569dd3f3-9052-426b-8135-a26ceb0fb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tons C02 emissions per capita \n",
    "# (note: multiply with 1,000,000 to convert from million ton to ton)\n",
    "df_co2['co2_pc'] = df_co2['co2_total'] * 1000000 / df_co2['population']\n",
    "\n",
    "df_co2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1fa8ac-d546-4ef1-bd9e-ac3964f2b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check: descriptives\n",
    "df_co2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7395f-9fd0-48d4-a1b9-0aae0475337c",
   "metadata": {},
   "source": [
    "**Task 2**: Use the country-level dataset from the previous task to visualize CO2 emissions across countries: \n",
    "\n",
    "1. Create a figure with two subplots:\n",
    "    - In the first subplot, show a scatter plot of total population (`population`) and per capita CO2 emissions (`co2_pc`).\n",
    "    - In the second subplot, show a histogram of the distribution of per capita CO2 emissions (`co2_pc`).\n",
    "   \n",
    "   From the plots, are there any outliers in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4738b876-7cd2-43a7-88f8-16a611640f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols = 2, figsize = (12, 4))\n",
    "\n",
    "# Scatter plot: total population vs per capita emissions\n",
    "ax[0].scatter(\n",
    "    df_co2['co2_pc'],\n",
    "    df_co2['population'] / 1000000,\n",
    "    s = df_co2['population'] / 10000000, # weight each country with its population\n",
    ")\n",
    "ax[0].set_xlabel('CO2 emissions (t CO2e/capita)')\n",
    "ax[0].set_ylabel('Total population (in millions)')\n",
    "ax[0].yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}')) \n",
    "\n",
    "# Histogram of per capita emissions\n",
    "ax[1].hist(df_co2['co2_pc'], bins = 30, density = True, edgecolor = 'black')\n",
    "ax[1].set_xlabel('CO2 emissions (t CO2e/capita)')\n",
    "ax[1].set_ylabel('Share of countries')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f5bcf-9e1e-4e10-a773-006cb9b0c3a4",
   "metadata": {},
   "source": [
    "Conclusion: Yes, there seems to be some outliers in the data. These are countries that either have very high populations but low per capita CO2 emissions, or high per capita CO2 emissions but low populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748dda9a-46fc-4e78-ab4f-cf4f496b1a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries with high per capita CO2 emissions (but low population)\n",
    "df_co2[df_co2['co2_pc'] > 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec562e21-09cc-4ff0-aa3d-c9925d11916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries with high population (but low per capita CO2 emissions)\n",
    "df_co2[df_co2['population'] > 400*1000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba66bf3-c4ad-478f-b0b4-f61ed3a5311c",
   "metadata": {},
   "source": [
    "2. Create a figure with 6 subplots (either 2x3 or 3x2):\n",
    "    - In each subplot, show a scatter plot of per capita CO2 emissions (`co2_pc`) and one of the potential explanatory variables of emissions (`urban`, `gdp_pc`, `electricity`, `agriculture`, `nat_resources`, `renew_energy`).\n",
    "    - Add the correlation coefficient between the explanatory variable and per capita CO2 emissions in the  title of the subplot.\n",
    "\n",
    "   *Hint*: To avoid using a nested `for` loop to generate the 2x3 or 3x2 plot, you can apply the `flatten` method on the `ax` object to create a one-dimensional object that you can use a single `for` loop to iterate over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22332f8f-72a2-4844-8504-c2ec218c08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 2, ncols = 3, sharey = True, figsize = (15, 8))\n",
    "\n",
    "# Flatten axes to one-dimensional object\n",
    "fax = ax.flatten()\n",
    "\n",
    "# Define explanatory variables and dict to use for nicer labels\n",
    "xvars = ['urban', 'gdp_pc', 'electricity', 'agriculture', 'nat_resources', 'renew_energy']\n",
    "d = {\n",
    "    'urban' : 'Urban population (% of total population)',\n",
    "    'gdp_pc' : 'GDP per capita (current US$)',\n",
    "    'electricity' : 'Access to electricity (% of population)',\n",
    "    'agriculture' : 'Agricultural land (% of land area)',\n",
    "    'nat_resources' : 'Total natural resources rents (% of GDP)',\n",
    "    'renew_energy' : 'Renew. energy cons. (% of total final energy cons.)'\n",
    "}\n",
    "\n",
    "for i in range(len(xvars)):\n",
    "\n",
    "    # Define variable to place on x-axis\n",
    "    xvar = xvars[i]\n",
    "\n",
    "    # Scatter plot between per capita CO2 emissions and xvar\n",
    "    fax[i].scatter(df_co2[xvar], df_co2['co2_pc'])\n",
    "\n",
    "    # Formatting\n",
    "    fax[i].set_ylabel('CO2 emissions (t CO2e/capita)')\n",
    "    fax[i].set_xlabel(d[xvar])\n",
    "    fax[i].set_title(f'Correlation: {df_co2['co2_pc'].corr(df_co2[xvar]):.2f}')\n",
    "\n",
    "plt.tight_layout() # improve spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e37f345-346f-4c6c-a583-d7e3f0799e95",
   "metadata": {},
   "source": [
    "**Task 3**: You will now estimate a multiple linear regression model where per-capita CO2 emissions (`co2_pc`) is the depdenent variable, and the model includes three out of the six potential explanatory variables: `urban`, `gdp_pc`, `electricity`, `agriculture`, `nat_resources`, `renew_energy`. \n",
    "\n",
    "*Note*: Do not include any polynomial terms in the model.\n",
    "\n",
    "In general, there are 20 possible combinations when you can choose three explanatory variables from six different variables. Your task is to find the combination of three variables that has the highest adjusted R-squared. \n",
    "\n",
    "Write a `for` loop in which you loop over the 20 possible combinations of three explanatory variables. For each possible combination:\n",
    "- Estimate the linear regression model: $co2\\_pc_i = \\alpha + \\beta_1 \\times X1_i + \\beta_2 \\times X2_i + \\beta_3 \\times X3_i$\n",
    "- Extract the adjusted R-squared from the model\n",
    "\n",
    "Which combination of explanatory variables has the highest adjusted R-squared?\n",
    "\n",
    "*Hint*: The function `combinations` from `itertools` can be used to generate all possible combinations from a set of values (see [here](https://www.geeksforgeeks.org/python/python-itertools-combinations-function/))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a534a2-6ea9-49a6-ac12-938a53883c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible explanatory variables\n",
    "xvars = ['urban', 'gdp_pc', 'electricity', 'agriculture', 'nat_resources', 'renew_energy']\n",
    "\n",
    "# Empty list to store combinations\n",
    "combs = []\n",
    "\n",
    "# Print and save each possible combination of 3 variables\n",
    "for comb in combinations(xvars, 3):\n",
    "    print(comb)\n",
    "    combs.append(comb)\n",
    "    \n",
    "print(len(combs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ef029-f256-4582-8eef-0902fa06102e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list to store adj. r-squared\n",
    "rsqr_lst = []\n",
    "\n",
    "for comb in combs:\n",
    "\n",
    "    # Generate formula from each tuple\n",
    "    formula = 'co2_pc ~ ' + comb[0] + ' + ' + comb[1] + ' + ' + comb[2]\n",
    "    \n",
    "    # Get adj. R-squared from linear regression model\n",
    "    # (Re-use get_rsqr function from task 2)\n",
    "    df_temp = df_co2.dropna(subset = ['co2_pc', comb[0], comb[1], comb[2]], axis = 0)\n",
    "    rsqr = get_rsqr(df_temp, formula)    \n",
    "    rsqr_lst.append(rsqr)\n",
    "    \n",
    "print(len(rsqr_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb718fd5-fefb-40cc-820e-73e0ca84dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max adj. R-squared\n",
    "max_r = max(rsqr_lst)\n",
    "\n",
    "# Find index of max adj. r-sqr\n",
    "index = rsqr_lst.index(max_r)\n",
    "\n",
    "# Find combination of that index\n",
    "comb = combs[index]\n",
    "\n",
    "print('The combination of explanatory variables with highest adj. R-sqr.:', comb)\n",
    "print('Adj. R-squared:', str(round(max_r, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c773221-af28-48ef-9fb1-534860a7c9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0d7b03-4e0c-42c8-88a6-819aae75c406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
